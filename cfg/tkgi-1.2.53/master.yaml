controls:
version: "tkgi-1.2.53"
id: 1
text: "主节点安全配置"
type: "master"
groups:
  - id: 1.1
    text: "主节点配置文件"
    checks:
      - id: 1.1.1
        text: "确保 API 服务器的 Pod 规范文件权限设置为 644 或更严格。"
        audit: stat -c permissions=%a /var/vcap/jobs/kube-apiserver/config/bpm.yml
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据系统中文件的位置）。例如，chmod 644 /var/vcap/jobs/kube-apiserver/config/bpm.yml
        scored: true

      - id: 1.1.2
        text: "确保 API 服务器 Pod 规范文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /var/vcap/jobs/kube-apiserver/config/bpm.yml
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据文件在您系统中的位置）。例如，chown root:root /var/vcap/jobs/kube-apiserver/config/bpm.yml
        scored: true

      - id: 1.1.3
        text: "确保控制器管理器 Pod 规范文件的权限设置为 644 或更严格。"
        audit: stat -c permissions=%a /var/vcap/jobs/kube-controller-manager/config/bpm.yml
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chmod 644 /var/vcap/jobs/kube-apiserver/config/bpm.yml
        scored: true

      - id: 1.1.4
        text: "确保控制器管理器 pod 规范文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /var/vcap/jobs/kube-controller-manager/config/bpm.yml
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（基于您系统上文件的位置）。例如，chown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml
        scored: true

      - id: 1.1.5
        text: "确保调度器 Pod 规范文件的权限设置为 644 或更严格。"
        audit: stat -c permissions=%a /var/vcap/jobs/kube-scheduler/config/bpm.yml
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据文件在您系统上的位置）。例如, chown 644 /var/vcap/jobs/kube-scheduler/config/bpm.yml
        scored: true

      - id: 1.1.6
        text: "确保调度程序 Pod 规范文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /var/vcap/jobs/kube-scheduler/config/bpm.yml
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据你系统上文件的位置）。例如，chown root:root /var/vcap/jobs/kube-scheduler/config/bpm.yml
        scored: true

      - id: 1.1.7
        text: "确保将 etcd pod 规范文件的权限设置为 644 或更加严格。"
        audit: stat -c permissions=%a /var/vcap/jobs/etcd/config/bpm.yml
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据系统上文件的位置）。例如，chmod 644 stat -c permissions=%a /var/vcap/jobs/etcd/config/bpm.yml
        scored: true

      - id: 1.1.8
        text: "确保 etcd Pod 规范文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /var/vcap/jobs/etcd/config/bpm.yml
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chown root:root /var/vcap/jobs/etcd/config/bpm.yml
        scored: true

      - id: 1.1.9
        text: "确保容器网络接口的文件权限设置为 644 或更加严格。"
        audit: find ((CNI_DIR))/config/ -type f -not -perm 640 | awk 'END{print NR}'
          | grep "^0$"
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据文件在您系统上的位置进行替换）。例如，chmod 644 <path/to/cni/files>
        scored: false

      - id: 1.1.10
        text: "确保容器网络接口文件的所有权设置为 root:root。"
        audit: find ((CNI_DIR))/config/ -type f -not -user root -or -not -group root
          | awk 'END{print NR}' | grep "^0$"
        type: manual
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chown root:root <path/to/cni/files>
        scored: false

      - id: 1.1.11
        text: "确保将 etcd 数据目录的权限设置为 700 或更严格。"
        audit: stat -c permissions=%a /var/vcap/store/etcd/
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "700"
        remediation: |-
          根据上面找到的 etcd 数据目录，运行以下命令。例如，chmod 700 /var/vcap/store/etcd/
        scored: true

      - id: 1.1.12
        text: "确保 etcd 数据目录的所有权设置为 etcd:etcd。"
        audit: stat -c %U:%G /var/vcap/store/etcd/
        type: manual
        tests:
          test_items:
            - flag: "etcd:etcd"
        remediation: |-
          根据上面找到的 etcd 数据目录，运行以下命令。例如，chown etcd:etcd /var/vcap/store/etcd/异常：所有的 bosh 进程都以 vcap 用户身份运行etcd 数据目录的所有权是 vcap:vcap
        scored: false

      - id: 1.1.13
        text: "确保 admin.conf 文件权限设置为 644 或更严格。"
        audit: stat -c permissions=%a /etc/kubernetes/admin.conf
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据您系统中文件的位置）。例如，chmod 644 /etc/kubernetes/admin.conf异常未使用 kubeadm 来进行集群的创建/引导。在主节点上不存在 kubeadm 和相关的配置文件。参考: https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.14
        text: "确保 admin.conf 文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /etc/kubernetes/admin.conf
        type: manual
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据系统中文件的位置）。例如，chown root:root /etc/kubernetes/admin.conf异常kubeadm 未用于配置/引导集群。 kubeadm 和相关配置文件不存在于主节点上。参考：https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.15
        text: "确保调度器配置文件的权限设置为 644。"
        audit: stat -c permissions=%a /etc/kubernetes/scheduler.conf
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chmod 644 /etc/kubernetes/scheduler.conf异常kubeadm 没有用于提供/引导集群。在主节点上不存在 kubeadm 和相关的配置文件。参考链接：https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.16
        text: "确保调度器配置文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /etc/kubernetes/scheduler.conf
        type: manual
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据您系统中文件的位置）。例如，chown root:root /etc/kubernetes/scheduler.conf异常kubeadm 未用于提供/引导集群。kubeadm 和相关的配置文件在主节点上不存在。参考: https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.17
        text: "确保控制器管理器配置文件的权限设置为 644。"
        audit: stat -c permissions=%a /etc/kubernetes/controller-manager.conf
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chmod 644 /etc/kubernetes/controller-manager.conf异常情况kubeadm 未用于创建/引导集群。 在主节点上不存在 kubeadm 和相关的配置文件参考：https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.18
        text: "确保控制器管理器配置文件的所有权设置为 root:root。"
        audit: stat -c %U:%G /etc/kubernetes/controller-manager.conf
        type: manual
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据您系统上文件的位置）。例如，chown root:root /etc/kubernetes/controller-manager.conf异常kubeadm 未用于提供/引导集群。 kubeadm 和相关配置文件不存在于主节点上。参考：https://kubernetes.io/docs/reference/setup-tools/kubeadm/implementation-details/#generate-kubeconfig-files-for-control-plane-components
        scored: false

      - id: 1.1.19
        text: "确保 Kubernetes PKI 目录和文件的所有权设置为 root:root。"
        audit: |
          find -L /var/vcap/jobs/kube-apiserver/config /var/vcap/jobs/kube-controller-manager/config /var/vcap/jobs/kube-
          scheduler/config ((CNI_DIR))/config /var/vcap/jobs/etcd/config | sort -u | xargs ls -ld | awk '{ print $3 " " $4}' |
          grep -c -v "root root" | grep "^0$"
        type: manual
        tests:
          test_items:
            - flag: "root:root"
        remediation: |-
          在主节点上运行以下命令（根据您系统中文件的位置）。例如，chown -R root:root /etc/kubernetes/pki/异常文件的组所有者是 vcap
        scored: false

      - id: 1.1.20
        text: "确保 Kubernetes PKI 证书文件的权限设置为 644 或更严格。"
        audit: |
          find -L /var/vcap/jobs/kube-apiserver/config \( -name '*.crt' -or -name '*.pem' \) -and -not -perm 640 | grep -v
          "packages/golang" | grep -v "packages/ncp_rootfs" | awk 'END{print NR}' | grep "^0$"
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          在主节点上运行以下命令（基于您系统上文件的位置）。例如，chmod -R 644 /etc/kubernetes/pki/*.crt例外忽略 packages/golang，因为该包包含 golang 使用的测试证书。忽略 packages/ncp_rootfs，在 TKG1 上使用 NSX-T 容器插件使用该包作为叠加文件系统 `mount | grep "packages/ncp_rootfs"`。
        scored: false

      - id: 1.1.21
        text: "确保将 Kubernetes PKI 密钥文件的权限设置为 600。"
        audit: |
          find -L /var/vcap/jobs/kube-apiserver/config -name '*.key' -and -not -perm 600 | awk 'END{print NR}' | grep "^0$"
        type: manual
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: eq
                value: "600"
        remediation: |-
          在主节点上运行以下命令（根据文件在您系统上的位置）。例如，chmod -R 600 /etc/kubernetes/pki/*.key特例将 etcd 的 .key 文件权限设置为 640，以允许 vcap 组读取访问。
        scored: false

  - id: 1.2
    text: "API 服务器"
    checks:
      - id: 1.2.1
        text: "确保将 --anonymous-auth 参数设置为 false。"
        audit: ps -ef | grep kube-apiserver | grep -- "--anonymous-auth=false"
        type: manual
        tests:
          test_items:
            - flag: "--anonymous-auth=false"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 的规范文件 kube-apiserver，并设置以下参数。--anonymous-auth=false异常该标志设置为 true 以启用 API 发现性。"从 1.6 版本开始，ABAC 和 RBAC 授权器要求明确授权 system:anonymous 用户或 system:unauthenticated 组，因此授予 * 用户或 * 组访问权限的传统策略规则不包括匿名用户。"-authorization-mode 设置为 RBAC
        scored: false

      - id: 1.2.2
        text: "确保未设置 --basic-auth-file 参数。"
        audit: ps -ef | grep kube-apiserver | grep -v -- "--basic-auth-file"
        tests:
          test_items:
            - flag: "--basic-auth-file"
              set: false
        remediation: |-
          按照文档说明配置替代的身份验证机制。然后，在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并移除 --basic-auth-file=<filename> 参数。
        scored: true

      - id: 1.2.3
        text: "确保 --token-auth-file 参数未设置。"
        audit: ps -ef | grep "/var/vcap/packages/kubernetes/bin/kube-apiserve[r]"
          | grep -v tini | grep -v -- "--token-auth-file="
        type: manual
        tests:
          test_items:
            - flag: "--token-auth-file"
              set: false
        remediation: |-
          按照文档的指导配置替代的身份验证机制。然后，在主节点上编辑 API 服务器 pod 的规格文件 /var/vcap/packages/kubernetes/bin/kube-apiserve[r]，移除 --token-auth-file=<filename> 参数。异常情况：由于 k8s 进程生命周期受 BOSH 管理，进程重新启动时需要基于令牌的身份验证。该文件权限为 0640，所有者为 root:vcap。
        scored: false

      - id: 1.2.4
        text: "确保将 --kubelet-https 参数设置为 true。"
        audit: ps -ef | grep kube-apiserver | grep -v -- "--kubelet-https=true"
        tests:
          test_items:
            - flag: "--kubelet-https=true"
        remediation: |-
          编辑主节点上的 API 服务器 Pod 规范文件 kube-apiserver，并移除 --kubelet-https 参数。
        scored: true

      - id: 1.2.5
        text: "确保将 --kubelet-client-certificate 和 --kubelet-client-key 参数设置为适当的值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -- "--kubelet-client-certificate=/var/vcap/jobs/kube-apiserver/config/kubelet-
          client-cert.pem" | grep -- "--kubelet-client-key=/var/vcap/jobs/kube-apiserver/config/kubelet-client-key.pem"
        type: manual
        tests:
          bin_op: and
          test_items:
            - flag: "--kubelet-client-certificate"
            - flag: "--kubelet-client-key"
        remediation: |-
          按照 Kubernetes 文档的指导，在 apiserver 和 kubelet 之间建立 TLS 连接。然后，在主节点上编辑 API server pod 的配置文件 kube-apiserver，并设置 kubelet 客户端证书和密钥参数如下。--kubelet-client-certificate=<path/to/client-certificate-file>--kubelet-client-key=<path/to/client-key-file>
        scored: false

      - id: 1.2.6
        text: "确保将 --kubelet-certificate-authority 参数设置为适当的值。"
        audit: ps -ef | grep kube-apiserver | grep -- "--kubelet-certificate-authority="
        type: manual
        tests:
          test_items:
            - flag: "--kubelet-certificate-authority"
        remediation: |-
          按照 Kubernetes 文档设置 apiserver 和 kubelet 之间的 TLS 连接。然后，在主节点上编辑 API server pod specification 文件 kube-apiserver，并将 --kubelet-certificate-authority 参数设置为证书颁发机构的证书文件路径。 --kubelet-certificate-authority=<ca-string>。异常 JIRA 问题单 #PKS-696 已创建用于调查解决。已打开 PR 来解决该问题：https://github.com/cloudfoundry-incubator/kubo-release/pull/179
        scored: false

      - id: 1.2.7
        text: "确保 API 服务器的授权模式中不包括 AlwaysAllow。"
        audit: |
          ps -ef | grep kube-apiserver | grep -- "--authorization-mode" && ps -ef | grep kube-apiserver | grep -v -- "--
          authorization-mode=\(\w\+\|,\)*AlwaysAllow\(\w\+\|,\)*"
        tests:
          test_items:
            - flag: "--authorization-mode"
              compare:
                op: nothave
                value: "AlwaysAllow"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并将 --authorization-mode 参数设置为除 AlwaysAllow 之外的其他值。一个示例可能如下所示。--authorization-mode=RBAC
        scored: true

      - id: 1.2.8
        text: "确保 --authorization-mode 参数包含 Node。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--authorization-mode=\(\w\+\|,\)*Node\(\w\+\|,\)* --"
        type: manual
        tests:
          test_items:
            - flag: "--authorization-mode"
              compare:
                op: has
                value: "Node"
        remediation: |-
          在主节点上编辑 API 服务器 pod 规范文件 kube-apiserver，并将 --authorization-mode 参数设置为包含 Node 的值。--authorization-mode=Node,RBAC异常可以使用 Kubernetes Profiles 添加此标志。请按照这里的说明进行操作https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html
        scored: false

      - id: 1.2.9
        text: "确保 --authorization-mode 参数包括 RBAC。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--authorization-mode=\(\w\+\|,\)*RBAC\(\w\+\|,\)*
          --"
        tests:
          test_items:
            - flag: "--authorization-mode"
              compare:
                op: has
                value: "RBAC"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并将 --authorization-mode 参数设置为一个包含 RBAC 的值，例如：--authorization-mode=Node,RBAC
        scored: true

      - id: 1.2.10
        text: "确保 admission 控制插件 EventRateLimit 被设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--enable-admission-plugins=\(\w\+\|,\)*EventRateLimit\
          (\w\+\|,\)*"
        type: manual
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: has
                value: "EventRateLimit"
        remediation: |-
          按照 Kubernetes 文档设置所需的限制在一个配置文件中。然后，编辑 API 服务器 pod 规范文件 kube-apiserver，并设置以下参数。--enable-admission-plugins=...,EventRateLimit,...--admission-control-config-file=<path/to/configuration/file>异常“注意：这是 Kubernetes v1.13 中的一个 Alpha 功能”Control 提供速率限制并且是特定于站点的。
        scored: false

      - id: 1.2.11
        text: "确保不设置 admission 控制插件 AlwaysAdmit。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v -- "--enable-admission-plugins=\(\w\+\|,\)*AlwaysAdmit\(\w\+\|,\)*"
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: nothave
                value: AlwaysAdmit
        remediation: |-
          在主节点上编辑 API 服务器的 Pod 规范文件 kube-apiserver，并且要么删除 --enable-admission-plugins 参数，要么设置为一个不包含 AlwaysAdmit 的值。
        scored: true

      - id: 1.2.12
        text: "确保 admission 控制插件 AlwaysPullImages 已设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--enable-admission-plugins=\(\w\+\|,\)*AlwaysPullImages\
          (\w\+\|,\)* --"
        type: manual
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: has
                value: "AlwaysPullImages"
        remediation: |-
          编辑主节点上的 API 服务器 Pod 规范文件 kube-apiserver，并将 --enable-admission-plugins 参数设置为包含 AlwaysPullImages。注意，对于已预加载映像且无法访问注册表以拉取正在使用映像的脱机或隔离集群，每次拉取私有映像都需要凭据。在受信任的环境中，此设置可能会增加对网络、注册表的负载并降低速度。此设置不适用于使用此配置的集群。TKGi 预装有映像。
        scored: false

      - id: 1.2.13
        text: "确保 admission 控制插件 SecurityContextDeny 被设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--enable-admission-plugins=\(\w\+\|,\)*SecurityContextDeny\
          (\w\+\|,\)* --"
        type: manual
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: has
                value: "SecurityContextDeny"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并设置 --enable-admission-plugins 参数以包含 SecurityContextDeny，除非已经存在 PodSecurityPolicy。--enable-admission-plugins=...,SecurityContextDeny,...例外此设置是特定于现场的。可以在适当的 "Plan" 的 "Admission Plugins" 部分中进行设置。
        scored: false

      - id: 1.2.14
        text: "确保 admission 控制插件 ServiceAccount 已设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--disable-admission-plugins=\(\w\+\|,\)*ServiceAccount\
          (\w\+\|,\)* --"
        tests:
          test_items:
            - flag: "--disable-admission-plugins"
              compare:
                op: nothave
                value: "ServiceAccount"
        remediation: |-
          根据文档创建与您的环境相符的 ServiceAccount 对象。然后，在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，确保将 --disable-admission-plugins 参数设置为一个不包含 ServiceAccount 的值。
        scored: true

      - id: 1.2.15
        text: "确保 admission control 插件 NamespaceLifecycle 已设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--disable-admission-plugins=\
          (\w\+\|,\)*NamespaceLifecycle\(\w\+\|,\)* --"
        tests:
          test_items:
            - flag: "--disable-admission-plugins"
              compare:
                op: nothave
                value: "NamespaceLifecycle"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并设置 --disable-admission-plugins 参数，确保它不包含 NamespaceLifecycle。
        scored: true

      - id: 1.2.16
        text: "确保 admission 控制插件 PodSecurityPolicy 已设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--enable-admission-plugins=\(\w\+\|,\)*PodSecurityPolicy\
          (\w\+\|,\)* --"
        type: manual
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: has
                value: "PodSecurityPolicy"
        remediation: |-
          按照文档的指导，在您的环境中创建 Pod 安全策略对象。然后，在主节点上编辑 API 服务器 Pod 的规范文件 kube-apiserver，并将 --enable-admission-plugins 参数设置为一个值，其中包括 PodSecurityPolicy: --enable-admission-plugins=...,PodSecurityPolicy,... 然后重启 API Server。特殊情况：此设置是特定于站点的。可以在相应“计划”的“准入插件”部分设置此设置。
        scored: false

      - id: 1.2.17
        text: "确保 admission 控制插件 NodeRestriction 已设置。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--enable-admission-plugins=\(\w\+\|,\)*NodeRestriction\
          (\w\+\|,\)* --"
        type: manual
        tests:
          test_items:
            - flag: "--enable-admission-plugins"
              compare:
                op: has
                value: "NodeRestriction"
        remediation: |-
          按照 Kubernetes 文档的指导，在 kubelet 上配置 NodeRestriction 插件。然后，在主节点上编辑 API 服务器 pod 规范文件 kube-apiserver，并将 --enable-admission-plugins 参数设置为一个值，其中包括 NodeRestriction。--enable-admission-plugins=...,NodeRestriction,...异常已打开 PR 来解决此问题 https://github.com/cloudfoundry-incubator/kubo-release/pull/179"
        scored: true

      - id: 1.2.18
        text: "确保未设置 --insecure-bind-address 参数。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--insecure-bind-address"
        tests:
          test_items:
            - flag: "--insecure-bind-address"
              set: false
        remediation: |-
          编辑主节点上的 API 服务器 Pod 规范文件 kube-apiserver，并移除 --insecure-bind-address 参数。
        scored: true

      - id: 1.2.19
        text: "确保将 --insecure-port 参数设置为 0。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--insecure-port=0"
        type: manual
        tests:
          test_items:
            - flag: "--insecure-port=0"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并设置以下参数。--insecure-port=0关于异常与 1.2.1 有关不安全端口是 8080，并且仅绑定到主节点上的 localhost，在主节点上由其他组件使用，绕过了身份验证/授权。连接到 APIServer 的组件有：kube-controller-managerkube-proxykube-schedulerPod 不会被调度到主节点上。
        scored: false

      - id: 1.2.20
        text: "确保 --secure-port 参数未设置为 0。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--secure-port=0"
        tests:
          test_items:
            - flag: "--secure-port"
              compare:
                op: noteq
                value: 0
        remediation: |-
          编辑主节点上的 API 服务器 Pod 规范文件 kube-apiserver，并删除 --secure-port 参数或将其设置为不同的（非零）期望端口。
        scored: true

      - id: 1.2.21
        text: "确保将 --profiling 参数设置为 false。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--profiling=false"
        tests:
          test_items:
            - flag: "--profiling=false"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并设置以下参数。--profiling=false
        scored: true

      - id: 1.2.22
        text: "确保将 --audit-log-path 参数设置为合适的数值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--audit-log-path=\/var\/vcap\/sys\/log\/kube-apiserver\/audit.log"
        type: manual
        tests:
          test_items:
            - flag: "--audit-log-path"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并将 --audit-log-path 参数设置为适当的路径和文件，用于指定想要写入审计日志的位置，例如：--audit-log-path=/var/log/apiserver/audit.log。
        scored: false

      - id: 1.2.23
        text: "确保 --audit-log-maxage 参数设置为 30 或者适当的数值。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--audit-log-maxage=30"
        type: manual
        tests:
          test_items:
            - flag: "--audit-log-maxage=30"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并将 --audit-log-maxage 参数设置为 30 天或适当的天数：--audit-log-maxage=30异常：这个设置可以通过 Kubernetes Profiles 设置为期望的值。请按照这里的说明操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html
        scored: false

      - id: 1.2.24
        text: "确保将 --audit-log-maxbackup 参数设置为 10 或适当的值。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--audit-log-maxbackup=10"
        type: manual
        tests:
          test_items:
            - flag: "--audit-log-maxbackup=10"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并将 --audit-log-maxbackup 参数设置为 10 或者适当的数值。--audit-log-maxbackup=10异常可以通过 Kubernetes Profiles 设置此值为期望值。请按照这里的说明操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html
        scored: false

      - id: 1.2.25
        text: "确保将 --audit-log-maxsize 参数设置为 100 或适当的值。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--audit-log-maxsize=100"
        type: manual
        tests:
          test_items:
            - flag: "--audit-log-maxsize=100"
        remediation: |-
          在主节点上编辑 API 服务器的 Pod 规范文件 kube-apiserver，并将 --audit-log-maxsize 参数设置为合适的大小（以 MB 为单位）。例如，要将其设置为 100 MB：--audit-log-maxsize=100异常可以使用 Kubernetes Profiles 将此设置设置为预期值。请按照这里的说明操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html
        scored: false

      - id: 1.2.26
        text: "确保将 --request-timeout 参数设置为适当的数值。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--request-timeout="
        type: manual
        tests:
          test_items:
            - flag: "--request-timeout"
        remediation: |-
          编辑 API 服务器 Pod 规范文件 kube-apiserver，并根据需要设置以下参数。例如，--request-timeout=300s。
        scored: false

      - id: 1.2.27
        text: "确保将 --service-account-lookup 参数设置为 true。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -v -- "--service-account-lookup"
        tests:
          test_items:
            - flag: "--service-account-lookup=true"
        remediation: |-
          在主节点上编辑 API 服务器 Pod 规范文件 kube-apiserver，并设置以下参数。--service-account-lookup=true或者，您可以从该文件中删除 --service-account-lookup 参数，使其采用默认设置。
        scored: true

      - id: 1.2.28
        text: "确保将 --service-account-key-file 参数设置为合适的数值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--service-account-key-file=/var/vcap/jobs/kube-
          apiserver/config/service-account-public-key.pem"
        type: manual
        tests:
          test_items:
            - flag: "--service-account-key-file"
        remediation: |-
          编辑主节点上的 API 服务器 pod 规范文件 kube-apiserver，并将 --service-account-key-file 参数设置为服务账户的公钥文件：<filename>。
        scored: false

      - id: 1.2.29
        text: "确保将 --etcd-certfile 和 --etcd-keyfile 参数设置为合适的数值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--etcd-certfile=/var/vcap/jobs/kube-apiserver/config/etcd-
          client.crt" | grep -- "--etcd-keyfile=/var/vcap/jobs/kube-apiserver/config/etcd-client.key"
        type: manual
        tests:
          bin_op: and
          test_items:
            - flag: "--etcd-certfile"
            - flag: "--etcd-keyfile"
        remediation: |-
          按照 Kubernetes 文档的指引，在 apiserver 和 etcd 之间建立 TLS 连接。然后，在主节点上编辑 API server 的 pod 规范文件 kube-apiserver，并设置 etcd 证书和密钥文件参数。--etcd-certfile=<path/to/client-certificate-file>--etcd-keyfile=<path/to/client-key-file>
        scored: false

      - id: 1.2.30
        text: "确保将 --tls-cert-file 和 --tls-private-key-file 参数设置为适当的值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--tls-cert-file=/var/vcap/jobs/kube-apiserver/config/kubernetes.pem" | grep -- "--tls-private-key-file=/var/vcap/jobs/kube-
          apiserver/config/kubernetes-key.pem"
        type: manual
        tests:
          bin_op: and
          test_items:
            - flag: "--tls-cert-file"
            - flag: "--tls-private-key-file"
        remediation: |-
          按照 Kubernetes 文档的指导，在 apiserver 上设置 TLS 连接。然后，在主节点上编辑 API 服务器 pod 的规范文件 kube-apiserver，设置 TLS 证书和私钥文件参数。--tls-cert-file=<path/to/tls-certificate-file>--tls-private-key-file=<path/to/tls-key-file>
        scored: false

      - id: 1.2.31
        text: "确保将 --client-ca-file 参数设置为适当的数值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--client-ca-file=/var/vcap/jobs/kube-apiserver/config/kubernetes-ca.pem"
        type: manual
        tests:
          test_items:
            - flag: "--client-ca-file"
        remediation: |-
          按照 Kubernetes 文档设置在 apiserver 上建立 TLS 连接。然后，在主节点上编辑 API 服务器 pod 规范文件 kube-apiserver，并设置客户端证书颁发机构文件。--client-ca-file=<path/to/client-ca-file>。
        scored: false

      - id: 1.2.32
        text: "确保将 --etcd-cafile 参数设置为适当的值。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--etcd-cafile=/var/vcap/jobs/kube-apiserver/config/etcd-ca.crt"
        type: manual
        tests:
          test_items:
            - flag: "--etcd-cafile"
        remediation: |-
          按照 Kubernetes 文档的指导，在 apiserver 和 etcd 之间建立 TLS 连接。然后，编辑主节点上的 API server Pod 规范文件 kube-apiserver，并设置 etcd 证书授权文件参数。--etcd-cafile=<path/to/ca-file>。
        scored: false

      - id: 1.2.33
        text: "确保 --encryption-provider-config 参数设置正确。"
        audit: |
          ps -ef | grep kube-apiserver | grep -v tini | grep -- "--encryption-provider-config="
        type: manual
        tests:
          test_items:
            - flag: "--encryption-provider-config"
        remediation: |-
          按照 Kubernetes 文档的指引配置一个 EncryptionConfig 文件。然后，在主节点上编辑 API 服务器的 Pod 规范文件 kube-apiserver，并将 --encryption-provider-config 参数设置为该文件的路径：--encryption-provider-config=</path/to/EncryptionConfig/File>。异常可以通过 Kubernetes Profiles 启用在 etcd 数据库中加密 Secrets。请按照这里的指示进行操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles-encrypt-etcd.html。
        scored: false

      - id: 1.2.34
        text: "确保将加密提供程序设置为 aescbc。"
        audit: |
          ENC_CONF=`ps -ef | grep kube-apiserver | grep -v tini | sed $'s/ /\\\\\\n/g' | grep -- '--encryption-provider-
          config=' | cut -d'=' -f2` grep -- "- \(aescbc\|kms\|secretbox\):" $ENC_CONF
        type: manual
        remediation: |-
          按照 Kubernetes 文档的指导配置一个 EncryptionConfig 文件。在该文件中，选择 aescbc、kms 或 secretbox 作为加密提供程序。注意：可以通过 Kubernetes Profiles 启用在 etcd 数据库中加密 Secrets。请按照以下说明操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles-encrypt-etcd.html
        scored: false

      - id: 1.2.35
        text: "确保 API 服务器仅使用强加密密码。"
        audit: ps -ef | grep kube-apiserver | grep -v tini | grep -- "--tls-cipher-suites="
        type: manual
        tests:
          test_items:
            - flag: "--tls-cipher-suites"
              compare:
                op: valid_elements
                value: "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256"
        remediation: |-
          编辑主节点上的 API 服务器 Pod 规范文件 /etc/kubernetes/manifests/kube-apiserver.yaml，并设置以下参数：--tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
        scored: false

  - id: 1.3
    text: "控制器管理器"
    checks:
      - id: 1.3.1
        text: "确保将 --terminated-pod-gc-threshold 参数设置为适当的值。"
        audit: ps -ef | grep kube-controller-manager | grep -- "--terminated-pod-gc-threshold=100"
        type: manual
        tests:
          test_items:
            - flag: "--terminated-pod-gc-threshold"
        remediation: |-
          在主节点上编辑 Controller Manager 的 Pod 规范文件 controller manager conf，并将 --terminated-pod-gc-threshold 设置为适当的阈值，例如：--terminated-pod-gc-threshold=10。
        scored: false

      - id: 1.3.2
        text: "确保控制器管理器的性能分析功能已禁用。"
        audit: ps -ef | grep kube-controller-manager | grep -- "--profiling=false"
        tests:
          test_items:
            - flag: "--profiling=false"
        remediation: |-
          在主节点上编辑 Controller Manager Pod 规范文件 controller-manager.conf，并设置以下参数。--profiling=false
        scored: true

      - id: 1.3.3
        text: "确保将 --use-service-account-credentials 参数设置为 true。"
        audit: ps -ef | grep kube-controller-manager | grep -- "--use\-service\-account\-credentials=true"
        tests:
          test_items:
            - flag: "--use-service-account-credentials=true"
        remediation: |-
          在主节点上编辑 Controller Manager 的 pod 规范文件 controller manager conf，设置以下参数：--use-service-account-credentials=true
        scored: true

      - id: 1.3.4
        text: "确保 --service-account-private-key-file 参数设置正确。"
        audit: |
          ps -ef | grep kube-controller-manager | grep -- "--service\-account\-private\-key\-file=\/var\/vcap\/jobs\/kube\-
          controller\-manager\/config\/service\-account\-private\-key.pem"
        type: manual
        tests:
          test_items:
            - flag: "--service-account-private-key-file"
        remediation: |-
          在主节点上编辑 Controller Manager 的 Pod 规范文件 controller manager conf，并将 --service-account-private-key-file 参数设置为服务账号的私钥文件。--service-account-private-key-file=<filename>
        scored: false

      - id: 1.3.5
        text: "确保 --root-ca-file 参数被设置为适当的数值。"
        audit: |
          ps -ef | grep kube-controller-manager | grep -- "--root\-ca\-file=\/var\/vcap\/jobs\/kube\-controller\-manager\/config\/ca.pem"
        type: manual
        tests:
          test_items:
            - flag: "--root-ca-file"
        remediation: |-
          在主节点上编辑 Controller Manager 的 Pod 规范文件 controller manager conf，并将 --root-ca-file 参数设置为证书捆绑文件`。--root-ca-file=<path/to/file>
        scored: false

      - id: 1.3.6
        text: "确保 RotateKubeletServerCertificate 参数设置为 true。"
        audit: |
          ps -ef | grep kube-controller-manager | grep -- "--feature-gates=\
          (\w\+\|,\)*RotateKubeletServerCertificate=true\(\w\+\|,\)*"
        type: manual
        tests:
          test_items:
            - flag: "--feature-gates=RotateKubeletServerCertificate=true"
        remediation: |-
          在主节点上编辑 Controller Manager 的 Pod 规范文件 controller manager conf，并设置 --feature-gates 参数，包括 RotateKubeletServerCertificate=true。--feature-gates=RotateKubeletServerCertificate=true异常证书轮转由 Credhub 处理。
        scored: false

      - id: 1.3.7
        text: "确保将 --bind-address 参数设置为 127.0.0.1。"
        audit: |
          ps -ef | grep "/var/vcap/packages/kubernetes/bin/kube-controller-manage[r]" | grep -v tini | grep -- "--bind-address=127.0.0.1"
        type: manual
        tests:
          test_items:
            - flag: "--bind-address=127.0.0.1"
        remediation: |-
          编辑主节点上的 Controller Manager pod 规范文件 controller manager conf，并确保 --bind-address 参数的正确值。异常可以使用 Kubernetes Profiles 将此设置设置为预期值。请按照以下说明进行操作 https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html
        scored: false

  - id: 1.4
    text: "调度器"
    checks:
      - id: 1.4.1
        text: "确保将 --profiling 参数设置为 false。"
        audit: ps -ef | grep kube-scheduler | grep -v tini | grep -- "--profiling=false"
        tests:
          test_items:
            - flag: "--profiling=false"
        remediation: |-
          编辑主节点上的调度器 Pod 规范文件 scheduler config file，并设置以下参数。--profiling=false
        scored: true

      - id: 1.4.2
        text: "确保将 --bind-address 参数设置为 127.0.0.1。"
        audit: ps -ef | grep "/var/vcap/packages/kubernetes/bin/kube-schedule[r]"
          | grep -v tini | grep -- "--bind-address=127.0.0.1"
        type: manual
        tests:
          test_items:
            - flag: "--bind-address"
              compare:
                op: eq
                value: "127.0.0.1"
        remediation: |-
          编辑主节点上的 Scheduler pod 规范文件 scheduler config，并确保 --bind-address 参数的正确值。异常情况可以使用 Kubernetes Profiles 来设置。请按照以下说明进行操作：https://docs.pivotal.io/tkgi/1-8/k8s-profiles.html.
        scored: false

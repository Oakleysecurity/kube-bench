controls:
version: rh-1.0
id: 4
text: "工作节点安全配置"
type: "node"
groups:
  - id: 4.1
    text: "工作节点配置文件"
    checks:
      - id: 4.1.1
        text: "确保 kubelet 服务文件的权限设置为 644 或更严格（自动）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n permissions=%a" /etc/systemd/system/kubelet.service 2> /dev/null
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          默认情况下，kubelet 服务文件的权限为 644。
        scored: true

      - id: 4.1.2
        text: "确保 kubelet 服务文件的所有权设置为 root:root（自动化）。"
        audit: |
          # Should return root:root for each node
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n %U:%G" /etc/systemd/system/kubelet.service 2> /dev/null
        tests:
          test_items:
            - flag: root:root
        remediation: |-
          默认情况下，kubelet 服务文件的所有权是 root:root。
        scored: true

      - id: 4.1.3
        text: "如果存在代理 kubeconfig 文件，请确保权限设置为 644 或更严格（手动）。"
        audit: |
          # Get the node name where the pod is running
          NODE_NAME=$(oc get pod "$HOSTNAME" -o=jsonpath='{.spec.nodeName}')
          # Get the pod name in the openshift-sdn namespace
          POD_NAME=$(oc get pods -n openshift-sdn -l app=sdn --field-selector spec.nodeName="$NODE_NAME" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

          if [ -z "$POD_NAME" ]; then
          echo "No matching pods found on the current node."
          else
          # Execute the stat command
          oc exec -n openshift-sdn "$POD_NAME" -- stat -Lc "$i %n permissions=%a" /config/kube-proxy-config.yaml  2>/dev/null
          fi
        tests:
          bin_op: or
          test_items:
            - flag: "permissions"
              set: true
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          不需要。
        scored: false

      - id: 4.1.4
        text: "确保代理 kubeconfig 文件的所有权设置为 root:root（手动）。"
        audit: |
          # Get the node name where the pod is running
          NODE_NAME=$(oc get pod "$HOSTNAME" -o=jsonpath='{.spec.nodeName}')
          # Get the pod name in the openshift-sdn namespace
          POD_NAME=$(oc get pods -n openshift-sdn -l app=sdn --field-selector spec.nodeName="$NODE_NAME" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

          if [ -z "$POD_NAME" ]; then
          echo "No matching pods found on the current node."
          else
          # Execute the stat command
          oc exec -n openshift-sdn "$POD_NAME"  -- stat -Lc "$i %n %U:%G" /config/kube-proxy-config.yaml  2>/dev/null
          fi
        use_multiple_values: true
        tests:
          bin_op: or
          test_items:
            - flag: root:root
        remediation: |-
          不需要任何操作。该配置由 OpenShift 运算符进行管理。
        scored: false

      - id: 4.1.5
        text: "确保 --kubeconfig kubelet.conf 文件权限设置为 644 或更严格（手动）。"
        audit: |
          # Check permissions
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n permissions=%a" /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          无需修改。
        scored: false

      - id: 4.1.6
        text: "确保 --kubeconfig kubelet.conf 文件的所有权设置为 root:root（手动）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n %U:%G" /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: root:root
        remediation: |-
          不需要。
        scored: false

      - id: 4.1.7
        text: "确保证书颁发机构文件的权限设置为 644 或更严格（自动化）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n permissions=%a" /etc/kubernetes/kubelet-ca.crt 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          不需要。
        scored: true

      - id: 4.1.8
        text: "确保客户端证书掼机构文件的所有权设置为 root:root（自动）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n %U:%G" /etc/kubernetes/kubelet-ca.crt 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: root:root
        remediation: |-
          不需要。
        scored: true

      - id: 4.1.9
        text: "确保 kubelet --config 的配置文件权限设置为 644 或更严格（自动化）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n permissions=%a" /var/lib/kubelet/kubeconfig 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: "permissions"
              compare:
                op: bitmask
                value: "644"
        remediation: |-
          无需操作。
        scored: true

      - id: 4.1.10
        text: "确保 kubelet 配置文件的所有权设置为 root:root（自动化）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host stat -c "$NODE_NAME %n %U:%G" /var/lib/kubelet/kubeconfig 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: root:root
        remediation: |-
          无需。
        scored: true

  - id: 4.2
    text: "Kubelet"
    checks:
      - id: 4.2.1
        text: "确保将 --anonymous-auth 参数设置为 false（自动化）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host grep -B4 -A1 anonymous /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: "enabled: true"
              set: false
        remediation: |-
          按照文档中的说明创建一个 Kubelet 配置 CRD，并将 anonymous-auth 设置为 false。
        scored: true

      - id: 4.2.2
        text: "确保 --authorization-mode 参数未设置为 AlwaysAllow（手动）。"
        type: manual
        # Takes a lot of time for connection to fail and
        audit: |
          POD=$(oc -n openshift-kube-apiserver get pod -l app=openshift-kube-apiserver -o jsonpath='{.items[0].metadata.name}')
          TOKEN=$(oc whoami -t)
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc exec -n openshift-kube-apiserver $POD -- curl -sS https://172.25.0.1/api/v1/nodes/$NODE_NAME/proxy/configz -k -H "Authorization:Bearer $TOKEN" | jq -r '.kubeletconfig.authorization.mode' 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: "Connection timed out"
        remediation: |-
          不需要。未经身份验证/未经授权的用户无法访问 OpenShift 节点。
        scored: false

      - id: 4.2.3
        text: "确保将 --client-ca-file 参数设置为适当的值（自动化）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host grep clientCAFile /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          test_items:
            - flag: '"clientCAFile": "/etc/kubernetes/kubelet-ca.crt"'
        remediation: |-
          无需更改。不支持更改 clientCAFile 值。
        scored: true

      - id: 4.2.4
        text: "验证只读端口未被使用或已设置为 0（自动化）。"
        audit: |
          echo `oc -n openshift-kube-apiserver get cm kube-apiserver-pod -o yaml | grep --color read-only-port` 2> /dev/null
          echo `oc -n openshift-kube-apiserver get cm config -o yaml | grep --color "read-only-port"` 2> /dev/null
        tests:
          bin_op: or
          test_items:
            - flag: "read-only-port"
              compare:
                op: has
                value: "[\"0\"]"
            - flag: "read-only-port"
              set: false
        remediation: |-
          在较早版本的 OpenShift 4 中，不使用 read-only-port 参数。请按照文档中的说明创建一个 Kubelet 配置 CRD，并将 --read-only-port 设置为 0。
        scored: true

      - id: 4.2.5
        text: "确保 --streaming-connection-idle-timeout 参数不设置为 0 (自动)。"
        audit: |
          # Should return 1 for node
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/${NODE_NAME} -- chroot /host ps -ef | grep kubelet | grep streaming-connection-idle-timeout 2> /dev/null
          echo exit_code=$?
          # Should return 1 for node
          oc debug node/${NODE_NAME} -- chroot /host grep streamingConnectionIdleTimeout /etc/kubernetes/kubelet.conf 2> /dev/null
          echo exit_code=$?
        use_multiple_values: true
        tests:
          bin_op: or
          test_items:
            - flag: --streaming-connection-idle-timeout
              compare:
                op: noteq
                value: 0
            - flag: streamingConnectionIdleTimeout
              compare:
                op: noteq
                value: 0s
            - flag: "exit_code"
              compare:
                op: eq
                value: 1
        remediation: |-
          按照文档中的说明创建一个 Kubelet 配置 CRD，并将 --streaming-connection-idle-timeout 设置为所需数值。不要将数值设置为 0。
        scored: true

      - id: 4.2.6
        text: "确保未设置 --protect-kernel-defaults 参数（手动）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/$NODE_NAME -- chroot /host more /etc/kubernetes/kubelet.conf 2> /dev/null
        tests:
          test_items:
            - flag: protectKernelDefaults
              set: false
        remediation: |-
          不需要。OpenShift 4 kubelet 会修改系统可调整参数；使用 protect-kernel-defaults 标志将导致 kubelet 在启动时失败，如果可调整参数与 kubelet 配置不匹配，则 OpenShift 节点将无法启动。
        scored: false

      - id: 4.2.7
        text: "确保将 --make-iptables-util-chains 参数设置为 true（手动）。"
        audit: |
          /bin/bash
          flag=make-iptables-util-chains
          opt=makeIPTablesUtilChains
          # look at each machineconfigpool
          while read -r pool nodeconfig; do
            # true by default
            value='true'
            # first look for the flag
            oc get machineconfig $nodeconfig -o json | jq -r '.spec.config.systemd[][] | select(.name=="kubelet.service") | .contents' | sed -n "/^ExecStart=/,/^\$/ { /^\\s*--$flag=false/ q 100 }"
            # if the above command exited with 100, the flag was false
            [ $? == 100 ] && value='false'
            # now look in the yaml KubeletConfig
            yamlconfig=$(oc get machineconfig $nodeconfig -o json | jq -r '.spec.config.storage.files[] | select(.path=="/etc/kubernetes/kubelet.conf") | .contents.source ' | sed 's/^data:,//' | while read; do echo -e ${REPLY//%/\\x}; done)
            echo "$yamlconfig" | sed -n "/^$opt:\\s*false\\s*$/ q 100"
            [ $? == 100 ] && value='false'
            echo "Pool $pool has $flag ($opt) set to $value"
          done < <(oc get machineconfigpools -o json | jq -r '.items[] | select(.status.machineCount>0) | .metadata.name + " " + .spec.configuration.name')
        use_multiple_values: true
        tests:
          test_items:
            - flag: "set to true"
        remediation: |-
          不需要任何操作。--make-iptables-util-chains 参数默认设置为 true。
        scored: false

      - id: 4.2.8
        text: "确保未设置 --hostname-override 参数（手动设置）。"
        audit: |
          echo `oc get machineconfig 01-worker-kubelet -o yaml | grep hostname-override`
          echo `oc get machineconfig 01-master-kubelet -o yaml | grep hostname-override`
        tests:
          test_items:
            - flag: hostname-override
              set: false
        remediation: |-
          默认情况下，--hostname-override 参数未设置。
        scored: false

      - id: 4.2.9
        text: "确保 kubeAPIQPS [--event-qps] 参数设置为 0 或确保适当的事件捕获级别（手动）。"
        audit: |
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/${NODE_NAME} -- chroot /host cat /etc/kubernetes/kubelet.conf;
          oc get machineconfig 01-worker-kubelet -o yaml | grep --color kubeAPIQPS%3A%2050
          oc get machineconfig 01-master-kubelet -o yaml | grep --color kubeAPIQPS%3A%2050
        type: "manual"
        remediation: |-
          请按照文档编辑 kubelet 参数https://docs.openshift.com/container-platform/4.5/scalability_and_performance/recommended-host-practices.html#create-a-kubeletconfig-crd-to-edit-kubelet-parametersKubeAPIQPS: <QPS>
        scored: false

      - id: 4.2.10
        text: "确保将 --tls-cert-file 和 --tls-private-key-file 参数设置为适当的值（自动化）。"
        audit: |
          oc get configmap config -n openshift-kube-apiserver -o json \
            | jq -r '.data["config.yaml"]' \
            | jq -r '.apiServerArguments |
                .["kubelet-client-certificate"][0],
                .["kubelet-client-key"][0]
              '
        tests:
          bin_op: and
          test_items:
            - flag: "/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt"
            - flag: "/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key"
        remediation: |-
          OpenShift 会自动管理 API 服务器与节点/Kubelet 之间的 TLS 认证。这是不可配置的。
        scored: true

      - id: 4.2.11
        text: "确保--rotate-certificates参数未设置为false（手动操作）。"
        audit: |
          #Verify the rotateKubeletClientCertificate feature gate is not set to false
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/${NODE_NAME} -- chroot /host cat /etc/kubernetes/kubelet.conf | grep RotateKubeletClientCertificate 2> /dev/null
          # Verify the rotateCertificates argument is set to true
          oc debug node/${NODE_NAME} -- chroot host grep rotate /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          bin_op: or
          test_items:
            - flag: rotateCertificates
              compare:
                op: eq
                value: true
            - flag: rotateKubeletClientCertificates
              compare:
                op: noteq
                value: false
            - flag: rotateKubeletClientCertificates
              set: false
        remediation: |-
          无需任何操作。
        scored: false

      - id: 4.2.12
        text: "验证 RotateKubeletServerCertificate 参数是否设置为 true (手动)。"
        audit: |
          #Verify the rotateKubeletServerCertificate feature gate is on
          NODE_NAME=$(oc get pod $HOSTNAME -o=jsonpath='{.spec.nodeName}')
          oc debug node/${NODE_NAME} -- chroot /host grep RotateKubeletServerCertificate /etc/kubernetes/kubelet.conf 2> /dev/null
          # Verify the rotateCertificates argument is set to true
          oc debug node/${NODE_NAME} -- chroot host grep rotate /etc/kubernetes/kubelet.conf 2> /dev/null
        use_multiple_values: true
        tests:
          bin_op: or
          test_items:
            - flag: rotateCertificates
              compare:
                op: eq
                value: true
            - flag: RotateKubeletServerCertificate
              compare:
                op: eq
                value: true
        remediation: |-
          默认情况下，kubelet 服务器证书轮换是禁用的。
        scored: false

      - id: 4.2.13
        text: "确保 Kubelet 仅使用强加密密码（手动）。"
        audit: |
          # needs verification
          # verify cipher suites
          oc describe --namespace=openshift-ingress-operator ingresscontroller/default
          oc get kubeapiservers.operator.openshift.io cluster -o json |jq .spec.observedConfig.servingInfo
          oc get openshiftapiservers.operator.openshift.io cluster -o json |jq .spec.observedConfig.servingInfo
          oc get cm -n openshift-authentication v4-0-config-system-cliconfig -o jsonpath='{.data.v4\-0\-config\-system\-cliconfig}' | jq .servingInfo
          #check value for tlsSecurityProfile; null is returned if default is used
          oc get kubeapiservers.operator.openshift.io cluster -o json |jq .spec.tlsSecurityProfile
        type: manual
        remediation: |-
          按照上述说明和 OpenShift 文档中的步骤来配置 tlsSecurityProfile。配置 Ingress。
        scored: false
